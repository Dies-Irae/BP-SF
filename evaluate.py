#Copyright (c) 2025 John Stack. All rights reserved.

import numpy as np
from codes_q import create_bivariate_bicycle_codes
from build_circuit import build_circuit, dem_to_check_matrices
from codes_q import create_bivariate_bicycle_codes
from ldpc.bp_decoder import BpDecoder
import matplotlib.pyplot as plt
import stim
import cudaq_qec as qec
import csv
import os
import time
import math
import cudaBPDecoder #our cuda code
import itertools
import random

def sample_n_choose_k(iterable, k, num_samples):
    """
    Samples k elements from an iterable n times.

    Args:
        iterable: The input iterable (e.g., list, tuple).
        k: The number of elements to choose in each combination.
        num_samples: The number of samples to generate.

    Returns:
        A list of tuples, where each tuple is a combination of k elements.
    """
    if k > len(iterable):
        raise ValueError("k cannot be greater than the length of the iterable")
    
    # Convert numpy array to list if necessary
    if isinstance(iterable, np.ndarray):
        iterable = iterable.tolist()
    
    num_comb = math.comb(len(iterable), k)
    if num_samples >= num_comb:
        all_combinations = list(itertools.combinations(iterable, k))
        return all_combinations
    
    if num_samples/num_comb < 0.001:
        # random sampling will very unlikely to generate
        # the same combination twice, so we can use it for large iterable
        samples = []
        for _ in range(num_samples):
            selected = random.sample(iterable, k)
            samples.append(tuple(selected))
        return samples
    else:
        all_combinations = list(itertools.combinations(iterable, k))
        return random.sample(all_combinations, num_samples)


def getTrainingData(circ, numShots):
    dem = circ.detector_error_model()
    chk, obs, priors, col_dict = dem_to_check_matrices(
        dem, return_col_dict=True)

    dem_sampler: stim.CompiledDemSampler = dem.compile_sampler()
    det_data, obs_data, err_data = dem_sampler.sample(
        shots=numShots, return_errors=False, bit_packed=False)

    return numShots, det_data, obs_data,chk,obs,priors

d=12 
n=144 
p=0.001
shots = 4000

#BBObj = create_bivariate_bicycle_codes(3, 3, [1,0], [1], [2], [0,2])
BBObj = create_bivariate_bicycle_codes(12, 6, [3], [1, 2], [1, 2], [3]) #Gross Code

code, A_list, B_list = BBObj
circ = build_circuit(code, A_list, B_list, 
                                    p=p, # physical error rate
                                    num_repeat=d, # usually set to code distance
                                    z_basis=True,   # whether in the z-basis or x-basis
                                    use_both=False, # whether use measurement results in both basis to decode one basis
                                )

#below line returns a detector check matrix corresponding to a d round STIM syndrome extraction circuit for the chosen BB code. det_data and obs_data are detector data and observable data for each shot, generated by STIM. 
#obs is the actual observable matrix (ie logical operators)
#priors is a vector where each entry corresponds to probability a detector is flipped. 

numShots, det_data, obs_data,chk,obs,priors = getTrainingData(circ, shots) 

chkDense = np.array(chk.todense())
chkDenseForNV = np.array(chk.todense(order='C'))

GPUBATCHSIZE = 1000 #how many syndromes go into GPU mem at once for our CUDA and NV CUDA. You will need to adjust this depending on code size.

start = time.time()
hard, soft, conv, osc = cudaBPDecoder.decode_bp_osc(chkDense, priors, det_data, np.array(obs.todense()), obs_data, max_iterations=100, batch_size=GPUBATCHSIZE)
for i, x in np.ndenumerate(np.where(conv == 0)):
    test_batch = np.zeros((100,priors.shape[0]))
    candidates = np.argsort(osc[x])[-50:]
    # print(osc[x][candidates])
    for w in range(1, 11):
        cols = np.array(sample_n_choose_k(candidates, w, 10))  # shape (10, w)
        rows = np.arange(10*(w-1), 10*w)[:, None]  # shape (10, 1)
        test_batch[rows, cols] = 1
    new_det_data = np.remainder(det_data[x] + test_batch @ chkDense.T, 2)
    hard[x], soft[x], conv[x], succ_i = cudaBPDecoder.decode_bp_early_stop(chkDense, priors, new_det_data, np.array(obs.todense()), obs_data[x], max_iterations=100, batch_size=GPUBATCHSIZE)
    if succ_i == -1:
        continue
    else:
        hard[x] = np.logical_xor(hard[x], test_batch[succ_i])

end = time.time()
myBPTime = end - start

print("Finished our CUDA decoding")

opts = dict() # see below for options
opts['error_rate_vec'] = priors
opts['max_iterations']=100
opts['use_osd']=True
opts['osd_method']=3
opts['osd_order']=10
opts['bp_batch_size']=GPUBATCHSIZE
opts['use_sparsity']=True

nvdec = qec.get_decoder('nv-qldpc-decoder', chkDenseForNV, **opts)

numberTimesConverge = 0
numberTimesConvergeNV = 0
numberTimesConvergeME = 0

num_errBP = 0
num_errME = 0
num_errNV=0


start = time.time()
nvResults   = nvdec.decode_batch(det_data)
#blah = 0
#for i in nvResults:
 #   blah = i.result
end = time.time()
nvBPTime = end - start
print("Finished NV decoding")

# bpTime = 0

myObj = BpDecoder(chk, error_rate=p, error_channel=priors, max_iter=100)
for i in range(shots):
    start = time.time()

    # bpOutput = myObj.decode(det_data[i]).astype(int)
    # end = time.time()

    # bpTime += end - start
    # if myObj.converge:
    #     numberTimesConverge += 1

    if nvResults[i].converged == True:
        numberTimesConvergeNV += 1

    if conv[i] == True:
        numberTimesConvergeME +=1

    # ansBP = (obs @ bpOutput + obs_data[i]) % 2 
    # num_errBP += ansBP.any()

    dec_result = np.array(nvResults[i].result, dtype=np.uint8)

    ansNV = (obs @ dec_result + obs_data[i]) % 2 
    num_errNV += ansNV.any()

    ansME = (obs @ hard[i] + obs_data[i]) % 2 
    num_errME += ansME.any() or not conv[i]

# print(numberTimesConverge)
print(numberTimesConvergeNV)
print(numberTimesConvergeME)

# print(num_errBP)
print(num_errNV)
print(num_errME)

# print("Joshka BP time: ", bpTime)

print("Our CUDA code time: ", myBPTime)
print("NV BP Time: ", nvBPTime)